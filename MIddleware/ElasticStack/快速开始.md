### 快速开始

#### 配置及目录结构

##### 配置文件

###### Elasticsearch 

*   配置文件

    ```shell
    # 允许自动创建 X-PACK 索引，* 允许自动创建所有索引的值
    vim elasticsearch.yml
    action.auto_create_index: .monitoring*,.watches,.triggered_watches,.watcher-history*,.ml*
    ```

*   Systemd 下服务及运行

    ```shell
    # 服务自启动
    sudo /bin/systemctl daemon-reload
    sudo /bin/systemctl enable elasticsearch.service
    # 自动重启
    sudo systemctl edit elasticsearch.service
    [Service]
    Restart=always
    sudo systemctl daemon-reload
    # 服务启动
    sudo systemctl start elasticsearch.service
    ```

*   安装插件

    *   中文分词插件

        ```shell
        # 中文分词
        ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.2.4/elasticsearch-analysis-ik-6.2.4.zip
        ```

        支持自定义分词词典，UTF-8 编码，一行一个自定义分词，修改 */etc/elasticsearch/analysis-ik/IKAnalyzer.cfg.xml*  配置文件并重启

        ```xml
        <!-- 将自定义字典文件放入 /etc/elasticsearch/analysis-ik 文件夹，并修改权限为读写 -->
        <entry key="ext_dict">project.dic</entry>
        ```

    *   sql 查询插件

        ```shell
        ./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.2.4.0/elasticsearch-sql-6.2.4.0.zip
        ```

        配置 web 站点

        下载 https://github.com/NLPchina/elasticsearch-sql/releases/download/5.4.1.0/es-sql-site-standalone.zip 并解压

        ```
        cd site-server
        npm install express --save
        node node-server.js
        ```

        修改 `elasticsearch.yml` 添加

        ```
        http.cors.enabled: true
        http.cors.allow-origin: "*"
        ```

        重启后访问，`http:ip:8080`，并修改顶部的地址为 elastic 地址

###### Logstash

配置文件位于 `/etc/logstash` 目录，包含以下配置文件

*   logstash.yml

    包含 Logstash 配置标志。可以在该文件中设置标志，而不是在命令行传递标志。在命令行中设置的任何标志都将覆盖文件中的相应设置

    *配置项*

    |              设置               |                             描述                             |                            默认值                            |
    | :-----------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
    |           `node.name`           |                       节点的描述性名称                       |                         机器的主机名                         |
    |           `path.data`           |          Logstash 及其插件用于任何持久性需求的目录           |                     `LOGSTASH_HOME/data`                     |
    |          `pipeline.id`          |                          管道的 ID                           |                            `main`                            |
    |       `pipeline.workers`        | 并行执行管道过滤器和输出阶段的工作人员数量。如果发现事件正在备份，或者CPU未饱和，请考虑增加此数量以更好地利用机器处理能力 |                     默认为 CPU 核心数据                      |
    |      `pipeline.batch.size`      | 在尝试执行过滤器和输出之前，单个工作线程从输入收集的最大事件数量。较大的批量大小通常效率更高，但会以增加的内存开销为代价。需要增加 `jvm.options` 配置文件中的 JVM 堆空间 |                             125                              |
    |     `pipeline.batch.delay`      | 在创建管道事件批次时，在将不足量的批次发送给管道工作人员之前，等待每个事件需要多长时间（毫秒） |                              50                              |
    |   `pipeline.unsafe_shutdown`    | 设置`true`为时，即使在内存中仍存在飞行中事件时，也会强制Logstash在关机期间退出。默认情况下，Logstash将拒绝退出，直到所有收到的事件都被推送到输出。启用此选项可能导致关机期间数据丢失。 |                            false                             |
    |          `path.config`          | 主管道的 `Logstash` 配置路径。 如果您指定目录或通配符，则会按字母顺序从目录中读取配置文件。 |                          特定于平台                          |
    |         `config.string`         | ‎一个字符串, 包含用于主管线的管线配置。使用与配置文件相同的语法。 |                             没有                             |
    |     `config.test_and_exit`      | 设置为时`true`，检查配置是否有效，然后退出。请注意，使用此设置不会检查grok图案的正确性。Logstash可以从目录读取多个配置文件。如果您将此设置与`log.level: debug`Logstash 结合使用，则Logstash会记录组合配置文件，并为每个配置块注释源自它的源文件 |                            false                             |
    |     `config.reload.automat`     | 设置 true 时，定期检查配置是否已更改，并在配置发生更改时重新加载配置。这也可以通过SIGHUP信号手动触发 |                            false                             |
    |     `config.reload.interva`     |             Logstash在几秒钟内检查配置文件的更改             |                              3s                              |
    |         `config.debug`          | 设置为时`true`，将完全编译的配置显示为调试日志消息。你还必须设置`log.level: debug`。警告：日志消息将包括任何以明文形式传递给插件配置的*密码*选项，并可能导致明文密码出现在您的日志中 |                            false                             |
    |    `config.support_escapes`     | 设置`true`为时，带引号的字符串将处理以下转义序列：`\n`成为文字换行符（ASCII 10）。`\r`成为一个文字回车（ASCII 13）。`\t`成为一个文字标签（ASCII 9）。`\\`成为文字反斜杠`\`。`\"`成为一个文字双引号。`\'`成为一个文字引号 |                            false                             |
    |            `modules`            |   配置时，`modules`必须位于本表上面描述的嵌套YAML结构中。    |                             没有                             |
    |          `queue.type`           | 用于事件缓冲的内部排队模型。指定`memory`传统基于内存的排队或`persisted`基于磁盘的确认排队（[持久队列](https://www.elastic.co/guide/en/logstash/current/persistent-queues.html)） |                           `memory`                           |
    |          `path.queue`           | 启用持续队列时数据文件存储的目录路径（`queue.type: persisted`）。 |                      ` path.data/queue`                      |
    |      `queue.page_capacity`      | 启用持久队列时使用的页面数据文件的大小（`queue.type: persisted`）。队列数据由分离为页面的仅附加数据文件组成。 |                             64mb                             |
    |        `queue.max_event`        | 启用持续队列时，队列中未读事件的最大数量（`queue.type: persisted`）。 |                          0（无限）                           |
    |        `queue.max_bytes`        | 队列的总容量（以字节数为单位）。确保磁盘驱动器的容量大于您在此处指定的值。如果同时`queue.max_events`和`queue.max_bytes`指定，Logstash采用的是先达到标准 |                         1024mb（1g）                         |
    |     `queue.checkpoint.acks`     | 启用持续队列时强制检查点之前的最大确认事件数（`queue.type: persisted`）。指定`queue.checkpoint.acks: 0`将此值设置为无限制 |                             1024                             |
    |    `queue.checkpoint.writes`    | 启用持久队列时强制检查点之前写入事件的最大数量（`queue.type: persisted`）。指定`queue.checkpoint.writes: 0`将此值设置为无限制 |                             1024                             |
    |          `queue_drain`          |       启用后，Logstash会在关闭之前等待持续队列被排空。       |                                                              |
    |   `dead_letter_queue.enable`    |           指示Logstash启用插件支持的DLQ功能的标志            |                            false                             |
    | ` dead_letter_queue.max_bytes ` | 每个死信队列的最大大小。如果这些条目超出此设置将增加死信队列的大小，则条目将被丢弃 |                            1024mb                            |
    |    `path.dead_letter_queue`     |             数据文件将存储在死信队列中的目录路径             |                `path.data/dead_letter_queue`                 |
    |           `http.host`           |                   指标REST端点的绑定地址。                   |                       ` "127.0.0.1" `                        |
    |           `http.port`           |                    指标REST端点的绑定端口                    |                             9600                             |
    |          ` log.level`           | 日志级别。有效的选项是：`fatal`  `error`  `warn`  `info`  `debug`  `trace` |                             info                             |
    |          `log.format`           | 日志格式。设置为`json`登录JSON格式，或`plain`使用`Object#.inspect` |                            plain                             |
    |           `path.logs`           |                 Logstash将其日志写入的目录。                 |                      LOGSTASH_HOME/logs                      |
    |         `path.plugins`          | 在哪里可以找到自定义插件。您可以多次指定此设置以包含多个路径。插件预计将在一个特定的目录层次结构：`PATH/logstash/TYPE/NAME.rb`其中`TYPE`是`inputs`，`filters`，`outputs`，或`codecs`，并且`NAME`是插件的名称 | 特定于平台的。请参阅[Logstash目录布局](https://www.elastic.co/guide/en/logstash/current/dir-layout.html)。 |

*   pipelines.yml

    包含在单个 Logstash 实例中运行多个管线的框架和说明

*   jvm.options

    包含 JVM 配置标志。使用此文件可以设置总堆空间的初始值和最大值。还可以使用此文件设置 Logstash 的区域设置。在单独的行上指定每个标志。

*   log4j2.properties

    包含库的默认设置。

*   startup.options

    linux 启动选项

###### 目录结构

* ElasticSearch 软件位置

    |  type   |                         description                          |          default location          |     setting      |
    | :-----: | :----------------------------------------------------------: | :--------------------------------: | :--------------: |
    |  home   |          elasticsearch home diretory or `$ES_HOME`           |     `/usr/share/elasticsearch`     |                  |
    |   bin   | 执行文件包含 elasticsearch 启动和 elasticsearch-plugin 安装插件 |   `/usr/share/elasticsearch/bin`   |                  |
    |  conf   |                    elasticsearch 配置文件                    |        `/etc/elasticsearch`        | `ES_PATCH_CONGF` |
    |  conf   | Environment variables including heap size, file descriptors. |    `/etc/default/elasticsearch`    |                  |
    |  data   | The location of the data files of each index / shard allocated on the node. Can hold multiple locations |      `/var/lib/elasticsearch`      |   `path.data`    |
    |  logs   |                      Log files location                      |      `/var/log/elasticsearch`      |    `path.log`    |
    | plugins | Plugin files location. Each plugin will be contained in a subdirectory | `/usr/share/elasticsearch/plugins` |                  |
    |  repo   | Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here. |           Not configured           |   `path.repo`    |

* kibana 目录

    |     type     |                         description                          |       default location       |   setting   |
    | :----------: | :----------------------------------------------------------: | :--------------------------: | :---------: |
    |     home     |           Kibana home directory or `$KIBANA_HOME`            |     `/usr/share/kibana`      |             |
    |     bin      | Binary scripts including `kibana` to start the Kibana server and `kibana-plugin` to install plugins |   ` /usr/share/kibana/bin`   |             |
    |    config    |          Configuration files including `kibana.yml`          |        `/etc/kibana`         |             |
    |     data     | The location of the data files written to disk by Kibana and its plugins |      `/var/lib/kibana`       | `path.data` |
    | **optimize** | Transpiled source code. Certain administrative actions (e.g. plugin install) result in the source code being retranspiled on the fly. | `/usr/share/kibana/optimize` |             |
    | **plugins**  | Plugin files location. Each plugin will be contained in a subdirectory | `/usr/share/kibana/plugins`  |             |

*   Logstash 目录结构

    |   类型   |                     描述                      |           默认位置            |             设置              |
    | :------: | :-------------------------------------------: | :---------------------------: | :---------------------------: |
    |   home   |                  软件家目录                   |     `/usr/share/logstash`     |                               |
    |   bin    |                二进制脚本目录                 |   `/usr/share/logstash/bin`   |                               |
    | settings | 配置文件（包含 logstash.yml, 与 jvm.options)  |        `/etc/logstash`        |        `path.settings`        |
    |   conf   |             logstash 管道配置文件             | `/etc/logstash/conf.d/*.conf` | `/etc/logstash/pipelines.yml` |
    |   logs   |                 日志文件目录                  |      `/var/log/logstash`      |          `path.logs`          |
    | plugins  |   本地，非Ruby-Gem 模块文件，仅用于开发环境   | `/usr/share/logstash/plugins` |        `path.plugins`         |
    |   data   | logstash 及其插件用于任何持久性需求的数据文件 |      `/var/lib/logstash`      |         ` path.data`          |

    ```shell
    # 测试配置
    bin/logstash -f first-pipeline.conf --config.test_and_exit
    # 启动并指定配置，--config.reload.automatic 允许自动重载配置
    bin/logstash -f first-pipeline.conf --config.reload.automatic
    ```

##### 配置

###### Elasticsearch 相关功能配置

*   集群环境下 *elasticsearch.yml* 文件选项配置

    *   ElasticStack 6.4 以前

        ```yaml
        # 每个节点的集群名称需要一致
        cluster.name: work
        # 节点名称，每个节点不一样
        node.name: node-1
        # 可访问网络地址，每个节点物理地址
        network.host: 192.168.10.10
        # http 请求端口默认 9200
        http.port: 9200
        # 节点发现网络地址,节点通信端口默认为 9300
        discovery.zen.ping.unicast.hosts: ["host1:9300", "host2:9300"]
        # 可被选举为主节点的数量,为了避免脑裂个数为 master-eligible nodes / 2 + 1 
        discovery.zen.minimum_master_nodes: 2
        # x-pack 配置
        xpack.security.enabled: false
        ```

    *   ElasticStack 6.4 以后

        ```yaml
        cluster.name: <cluster.name>
        node.name: <node.name>
        path.data: /var/lib/elasticsearch
        path.logs: /var/log/elasticsearch
        network.host: 0.0.0.0
        http.port: 9200
        http.cors.enabled: true
        http.cors.allow-origin: "*"
        # 发现节点
        discovery.seed_hosts:
          - <node.ip:port>
          - <node.ip:port>
          - <node.ip:port>
        # 可以被选举为主节点的主机
        cluster.initial_master_nodes:
          - <node.name>
          - <node.name>
          - <node.name>
        ```

        必须是新启动节点，如果已生成节点后再配置 `discovery.seed_hosts` 则无法发现节点，因为原

        来的集群 id 不同。删除 `/var/lib/elasticsearch` 中文件即可

*   安全相关配置

    1.  仅将 host 绑定到本地或内网地址

        ```yaml
        # elasticsearch.yml
        network.host: 127.0.0.1  // 或内网地址
        ```

    2.  防火墙相关配置

        ```shell
        # 限制9200-集群对外访问端口
        iptables -A INPUT -i eth0 -p tcp --destination-port 9200 -s {PUBLIC-IP-ADDRESS-HERE} -j DROP
        # 限制9200-集群对外访问端口
        iptables -A INPUT -i eth0 -p tcp --destination-port 9300 -s {PUBLIC-IP-ADDRESS-HERE} -j DROP
        # 限制5601-kibana访问端口
        iptables -A INPUT -i eth0 -p tcp --destination-port 5601 -s {PUBLIC-IP-ADDRESS-HERE} -j DROP
        ```

    3.  两天机器建立安全 SSH 隧道

        ```shell
        ssh -Nf -L 9200:localhost:9200 user@remote-elasticsearch-server
        curl http://localhost:9200/_search
        ```

    4.  nginx 代理配置

        ```shell
        # 生成密码文件
        printf "esuser:$(openssl passwd -crypt MySecret)\n" > /etc/nginx/passwords
        # 生成自签名SSL证书
        sudo mkdir /etc/nginx/ssl
        sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/nginx/ssl/nginx.key -out /etc/nginx/ssl/nginx.crt
        ```

        nginx 代理配置

        ```nginx
        http {
            upstream elasticsearch {
                server 127.0.0.1:9200;
            }
        }
        server {
            # enable TLS
            listen 0.0.0.0:443 ssl;
            ssl_certificate /etc/nginx/ssl/nginx.crt;
            ssl_certificate_key /etc/nginx/ssl/nginx.key;
            ssl_protocols TLSv1.2;
            ssl_prefer_server_ciphers on;
            ssl_session_timeout 5m;
            ssl_ciphers "HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES";
            # Proxy for Elasticsearch
            location / {
                auth_basic "Login";
                auth_basic_user_file passwords;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header Host $http_host;
                proxy_set_header X-NginX-Proxy true;
                # use defined upstream with the name "elasticsearch"
                proxy_pass http://elasticsearch/;
                proxy_redirect off;
                if ($request_method = OPTIONS ) {
                    add_header Access-Control-Allow-Origin "*"; 
                    add_header Access-Control-Allow-Methods "GET, POST, , PUT, OPTIONS";
                    add_header Access-Control-Allow-Headers "Content-Type,Accept,Authorization, x-requested-with"; 
                    add_header Access-Control-Allow-Credentials "true"; 
                    add_header Content-Length 0;
                    add_header Content-Type application/json;
                    return 200;
            }
        }
        ```

        