## MySQL 锁机制

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁

### 全局锁

全局锁就是对整个数据库实例加锁。`MySQL` 提供了一个加全局读锁的方法，命令是 `flush tables with read lock`（`FTWRL`）。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句

全局锁的典型使用场景是，做全库逻辑备份。即把整库每个表都 `select` 出来存成文本

但让整库都只读，会造成：

* 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆
* 如果在从库上备份，那么备份期间从库不能执行主库同步过来的 `binlog`，会导致主从延迟

但不加锁，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。可以使用，在可重复读隔离级别下开启一个事务，拿到一致性视图的。

官方自带的逻辑备份工具是 `mysqldump`。当 `mysqldump` 使用参数 `-single-transaction` 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 `MVCC` 的支持，这个过程中数据是可以正常更新的。`single-transaction` 方法只适应于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 `FTWRL` 方法。

一致性读的前提是引擎要支持这个隔离级别。比如，对于 `MyISAM` 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，就需要使用 `FTWRL` 命令了。

全库只读，可以使用 `set global readonly=true` 的方式。`readonly` 方式可以让全库进入只读状态，但建议使用 `FTWRL` 方式，主要有两个原因

* 有些系统中，`readonly` 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 `global` 变量的方式影响面更大。
* 在异常处理机制上有差异。如果执行 `FTWRL` 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 `readonly` 之后，如果客户端发生异常，则数据库就会一直保持 `readonly` 状态，这样会导致整个库长时间处于不可写状态，风险较高

业务的更新不只是增删改数据（DML），还有可能是加字段等修改表结构的操作（DDL）。不论是那种方法，一个库被全局锁上以后，要对里面任何一个表做加字段操作，都是会被锁住的。

### 表级锁

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL）

表锁的语法是 `lock tables ... read/write`。与 `FTWRL` 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

如果在某个线程 A 中执行 `lock tables t1 read, t2 write` ；这个语句，则其他线程写 `t1`、读写 `t2` 的语句都会被阻塞。此时，线程 A 在执行 `unlock tables` 之前，也只能执行读 `t1`、读写 `t2` 的操作。写 `t1` 都不允许，自然不能访问其他表。

在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 `InnoDB` 这种支持行锁的引擎，一般不使用 `lock tables` 命令来控制并发，毕竟锁住整个表的影响面还是太大

另一类表级别的锁是 MDL （metadata data lock）。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定不对。

因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当对表做结构变更操作时，加 MDL 写锁

* 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查
* 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

虽然 MDL 锁是系统默认会加的，但事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

如何安全地给小表加字段

1. 解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 `information_schema` 库的 `innodb_trx` 表中，可以查到当前执行中的事务。如果要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 `Kill` 掉这个长事务。

如果要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而不得不加个字段：这时候 `kill` 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 `alter table` 语句里面设定等待时间，如果在这个指定的等待时间里能够拿到 MDL 写锁最后，拿不到也不要阻塞后面的业务语句，先放弃。之后 DBA 再通过重试命令重复这个过程

```mysql
ALTER TABLE tb1_name NOWAIT add column ...
ALTER TABLE tb1_name WAIT N add column ...
```

全局锁主要用在逻辑备份过程中。对于全剧是 `InnoDB` 引擎的库，使用 `-single-transaction` 参数，对应用会更好。

表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果程序里有 `lock tables` 的语句，比较可能的情况是：

* 系统现在还在用 `MyISAM` 这类不支持事务的引擎
* 引擎升级了，但是代码还没升级，业务开发需将`lock tables`  和 `unlock tables` 改成 `begin` 和 `commit`

### 行锁

#### 两阶段锁

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，`MyISAM` 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。`InnoDB` 是支持行锁的。

行锁就是针对数据表中行记录的锁。即：事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等到事务 A 的操作完成后才能更新

**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等待事务结束时才释放。这就是两阶段锁协议** ，如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

#### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

出现死锁后，执行 `show engine innodb status` 命令得到的部分输出。这个命令会输出很多信息。有一节 `LATESTDETECTED DEADLOCK`， 就是记录的最后一次死锁的信息

​	*死锁现场*

​	![](../Images/Performance/死锁现场.png)

这个结果分成三部分：

* （1）`TRANSACTION`，是第一个事务的信息
* （2）`TRANSACTION`，是第二个事务的信息
* `WE ROLL BACK TRANSACTION (1)`，是最终的处理结果，表示回滚了第一个事务

第一个事务的信息中：

* `WAITING FOR THIS LOCK TO BE GRANTED`，表示的是这个事务在等待的锁信息
* `index c of table test.t`，说明在等的是表 t 的索引 c 上面的锁
* `lock mode S waiting` 表示这个语句要自己加一个读锁，当前的状态是等待中；
* `Record lock`  说明这是一个记录锁
* `n_fields 2` 表示这个记录是两列，就是字段 c 和主键字段 id;
* `0: len 4; hex 0000000a；asc;;` 是第一个字段，也就是 c 。值是十六进制 a，就是 10
* `1: len 4; hex 0000000a; asc;;` 是第二个字段，也就是主键 id，值也是 10；
* 这两行里面的 `asc` 表示的是，接下来要打印出值里面的 “可打印字符”，但 10 不是可打印字符，因此就显示空格
* 第一个事务信息就只显示出了等锁的状态，在等待 （c = 10,id = 10）这一行的锁
* 当然既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。

第二个事务显示的信息要多一些：

* `HOLDS THE LOCK(S)` 用来显示这个事务持有那些锁
* `index c of table test.t` 表示锁是在表 t 的索引 c 上；
* `hex 0000000a` 和 `hex 00000014` 表示这个事务持有 `c = 10` 和 `c = 20 ` 这两个记录锁
* `WAITING FOR THIS LOCK TO BE GRANTED`，表示在等（`c=5, id = 5`）这个记录锁

上图中：

1. `lock in share mode` 的这个语句，持有 c = 5 的记录锁，在等 c = 10 的锁
2. `for update` 这个语句，持有 c = 20 和 c = 10 的记录锁，在等 c = 5 的记录锁

因此导致了死锁。

1.由于锁是一个个加到，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；

2.在发生死锁的时刻，`for update` 这条语句占用的资源更多，回滚成本更大，所以 `Innodb` 选择了回滚成功更小的 `lock in share mode` 语句，来回滚。

*资源依赖引发的锁冲突*

![](../Images/Performance/资源依赖引发锁冲突.jpg)

事务 A 在等待事务 B 释放 id = 2 的行锁，而事务 B 在等待事务 A 释放 id = 1 的行锁。事务 A 和事务 B 在互相等待对方的资源释放，就进入了死锁状态。当出现死锁以后，有两种策略：

* 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 
* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，即开启死锁检测

在 `InnoDB` 中，`innodb_lock_wait_timeout` 的默认值是 50s，即如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。但是，不能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实可以很快解开，但如果不是死锁，而是简单的锁等待。所以，超时时间设置太短的话，会出现很多误伤。

正常情况下采用第二种策略：主动死锁检测。而且 `innodb_deadlock_detect` 的默认值本身就是 `on`，主动死锁检测在发送死锁的时候，是能够快速发现并进行处理的，但是它有额外负担（每当一个事务被锁时，就会检测它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了死锁）。每个新来的被堵住的线程，都要判断会不会由于自己的加入导致死锁，这是一个时间复杂度是 `O(n)` 的操作。虽然最终检查的结构是没有死锁，但是这期间要消耗大量 CPU 资源。因此会出现 CPU 利用率很高，但是每秒却执行不了几个事务）解决办法为：

* 如果能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但这种本身带有一定风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题，这是业务无损的。而关掉死锁检测意味着可能出现大量的超时，这是业务有损的。
* 控制并发度：如果并发度能够控制住，比如同一行时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，不太可行，因为客户端很多。每个客户端汇总到数据库服务端以后的峰值并发数也会很高。因此，这个并发控制要做在数据库服务端。如果有中间件，可以考虑在中间件实现，也可修改 MySQL 源码，做在 MySQL 里面。基本思路是一致的：**对于相同行的更新，在进入引擎之前排队。这样在 `InnoDB` 内部就不会有大量的死锁检测工作了。** 还可以通过在设计上的冗余来减少锁冲突：时间复杂度为 `O(logn)` ：将一行改成逻辑上的多行来减少锁冲突。（如需频繁更新客户余额，可以考虑放在多条记录上，比如 10 个记录，这样每次增加影客户余额时，随机选一行记录来加。这样每次冲突概率变成原来的 1/10）

#### 如何减少或避免死锁

* 如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽可能往后放。
* 减少死锁的主要方向，就是控制访问相同资源的并发事务量。

### 自增锁

#### 自增值保存策略

不同的引擎对于自增值的保存策略不同

* MyISAM 引擎的自增值保存在数据文件中
* InnoDB 引擎的自增值，在 5.7 及之前版本，自增值保存在内存里，每次重启后，第一次打开表的时候，都会去找自增值的最大值 Max(id)，然后将 `max(id) + 1` 作为这个表当前的自增值。8.0 版本，将自增值的变更记录在了 `redo log` 中，重启的时候依靠 `redo log` 恢复重启之前的值

#### 自增值修改机制

在 MySQL 里面，如果字断 id 被定义为 `AUTO_INCREMENT`，在插入一行数据的时候，自增值的行为如下：

1.如果插入数据时 id 字断指定为 0，null 或者未指定值，那么就把这个表当前的 `AUTO_UNCREMENT` 值填到自增字断

2.如果插入数据时 id 字断指定了具体的值，就直接使用语句里指定的值

根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是 X，当前的自增值是 Y。如果 X < Y，那么这个表的自增值不变，如果 X >= Y，就需要把当前自增值修改新的自增值。

新的自增值生成算法是：从 `auto_increment_offset` 开始，以 `auto_increment_increment` 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值（`auto_increment_offset` 和 `auto_increment_increment` 是两个系统参数，分别用来表示自增的初始值和步长）

#### 自增值的修改时机

唯一键冲突时导致自增主键 id 不连续，事务回滚也会产生类似的现象。innodb 语句执行失败也不回退自增 id。因此不能保证自增主键 id 是连续的。对于预先不知道插入多少数据的批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：

1.语句执行过程中，第一次申请自增 id，会分配 1 个；

2.1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；

3.2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；

4.依次类推，用一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍

但申请后没用完的自增主键 id 记录就不会会退，因此，这是主键 id 出现自增 id 不连续的第三种原因。

#### 自增锁优化

自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。在 5.1 版本之前，自增锁是语句级别的（如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放）

5.1.22 版本引入了新策略，新增参数 `innodb_autoinc_mode`，默认值是 1

* 这个参数的值被设置成  0 时，表示采用之前 5.0 版本的策略，即语句执行结束后才释放锁
* 这个参数的值被设置为 1 时：普通 `insert` 语句，自增锁在申请之后就马上释放，类似 `insert...select` 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放
* 这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁

**在生产上，尤其有 insert ... select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，innodb_autoinc_lock_mode=2，并且 binlog_format=row**这样既能提升并发性，又不会出现数据一致性问题。（批量插入数据，包含的语句类型是 `insert ...select`，`replace ...select` 和 `load data` 语句。但是，在普通的 insert 语句里面包含多个 value 的值的情况下，即是 `innodb_autoinc_lock_mode` 设置为 1，也不会等语句执行完成后才释放锁。这类语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就释放了。

